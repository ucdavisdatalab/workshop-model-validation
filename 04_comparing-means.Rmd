```{r load-libraries, echo=FALSE, warning=FALSE,include=FALSE}
library("readr")
library( "lubridate" )
library( "dplyr" )
library( "gbm" )


# import the gbsg data
gbsg = read_csv( "data/gbsg.csv" )

# make a factor of the grade
gbsg$grade = factor( gbsg$grade )

# generate the variable `fys`, to indicate five year recurrence-free survival:
gbsg$fys = with(gbsg, ifelse( rfstime > 365*5, 1, ifelse(status == 0, NA, 0)))



# import the covid dataset
covid = read_csv( "data/covid.csv" )

# add the date column to the covid data
# covid$date = mdy( covid$SOURCE_DATA_DATE )

# make day of the week a factor
# covid$DAY_OF_THE_WEEK = factor( covid$DAY_OF_THE_WEEK )


```

# Validating the model's functional form
We can validate the model's functional form by making predictions and comparing them to the truth. If the estimated mean function is valid, then the observed should be in line with predictions. Of course, there will stil be some error, but the predictions should be accurate on average.


## Posit a model
To posit a model here means to select a model form and distribution, and apply them to a piece of estimation software. Most often the model form is a generalized linear model (which includes linear regression as a special case), but we are also looking at random forest-type models, which are not linear in their inputs.

### Model form
Selecting a model form includes deciding which covariates have a predictive relationship with the response, and whether their relationship is linear, linear following some transformation, or should be modeled more flexibly, e.g. with a tree-based approach.

### Model distribution
Knowing the allowable range of the response will help you to decide what distribution to specify in fitting a model. Here are some common, crucial decision points:

- If the response is in the form of "number of events out of some number of tries" (e.g. a basketball player's free throw percentage is the number of made free throws out of tries), then a binomial distribution may be appropriate. This is also the case when the number of "tries" is one - as in our example of five years survival for women with breast cancer. Here, the "event" is "the woman survives five years after diagnosis", and each person in the study gets one try.
- If the response is a count of independent events, with no "out of" tries, then it may be Poisson distributed.
- If the data are continuous with no bounds then they may be normally distributed.
- If the data are continuous, but have a defined lower bound at zero then they may follow a Gamma distribution.


## Validate the assumptions
Having posited a model, we may check whether the model generates fits and predictions that agree with the assumptions. Let's do this for our examples.

```{r mean-validation-cars}
nfold = 5
folds = sample( 1:nfold, size=nrow(cars), replace=TRUE )

preds = list( 'a' = numeric(nrow(cars)), 'b' = numeric(nrow(cars)), 'c' = numeric(nrow(cars)), 'd' = numeric(nrow(cars)) )

for ( i in 1:nfold ) {
  # Estimate a model for the stopping distance data
  lm1 = lm( dist ~ speed, data=cars[ folds!= i, ] )
  lm2 = lm( dist ~ I(speed^2), data=cars[ folds!= i, ] )
  lm3 = lm( dist ~ I(speed^3), data=cars[ folds!= i, ] )
  lm4 = lm( dist ~ I(speed^2) + 0, data=cars[ folds!= i, ] )
    
  
  preds[['a']][ folds == i ] = predict( lm1, cars[ folds==i, ] )
  preds[['b']][ folds == i ] = predict( lm2, cars[ folds==i, ] )
  preds[['c']][ folds == i ] = predict( lm3, cars[ folds==i, ] )
  preds[['d']][ folds == i ] = predict( lm4, cars[ folds==i, ] )
}

# calculate the mean squared error of the models
var( preds[['a']] - cars$dist )
var( preds[['b']] - cars$dist )
var( preds[['c']] - cars$dist )
var( preds[['d']] - cars$dist )
```


```{r mean-validation-gbsg}
nfold = 5
folds = sample( 1:nfold, size=nrow(gbsg), replace=TRUE )

preds = list( 'a' = numeric(nrow(gbsg)), 'b' = numeric(nrow(gbsg)), 'c' = numeric(nrow(gbsg)), 'd' = numeric(nrow(gbsg)) )

for ( i in 1:nfold ) {
  # Estimate a model for the stopping distance data
  glm1 = glm( fys ~ age + meno + size + grade + log(nodes) + sqrt(pgr) + sqrt(er) + hormon, data=gbsg[ folds!= i, ], family='binomial' )
  # glm2 = glm( fys ~ I(speed^2), data=gbsg[ folds!= i, ], family='binomial' )
  # glm3 = glm( fys ~ I(speed^3), data=gbsg[ folds!= i, ], family='binomial' )
  # glm4 = glm( fys ~ I(speed^2) + 0, data=gbsg[ folds!= i, ], family='binomial' )
    
  
  preds[['a']][ folds == i ] = predict( glm1, gbsg[ folds==i, ], type='response' )
  # preds[['b']][ folds == i ] = predict( glm2, gbsg[ folds==i, ], type='response' )
  # preds[['c']][ folds == i ] = predict( glm3, gbsg[ folds==i, ], type='response' )
  # preds[['d']][ folds == i ] = predict( glm4, gbsg[ folds==i, ], type='response' )
}

# calculate the mean squared error of the models
var( (preds[['a']] - gbsg$fys) / sqrt(preds[['a']] * (1-preds[['a']])), na.rm=TRUE )
# var( preds[['b']] - gbsg$fys )
# var( preds[['c']] - gbsg$fys )
# var( preds[['d']] - gbsg$fys )
```


#### COVID-19 admissions example

Recall that one of our first validation tasks for the COVID-19 admissions data was to check whether the time series was autocorrelated. We concluded that there was not an important amount of autocorrelation, and so we will use modeling methods that treat the data as independent. Despite that, when the data are a time series, it is good practice to do cross-validation by a walkforward approach. That means that the folds should be contiguous time blocks of data, and each iteration of the cross-valdation should be trained only on past data, and used to predict future data.

Here, we use walkforward six-fold cross-validation to assess whether the fitted model generates predictions that are on average accurate to the observed future values.

```{r mean-validation-covid}
set.seed(20211108)

covid$D1_admissions = lead(covid$COVID_NEW_ADM_CNT, 1)
covid = covid[ rowSums( is.na(covid)) == 0, ]

# how many CV folds
nfold = 5

# create walkforward CV folds
fold = rep( 0:nfold, each=nrow(covid) %/% (nfold+1) )
fold = c( rep( 0, nrow(covid)-length(fold) ), fold )

# prepare an object to hold the predictions
pred = rep( NA, nrow(covid) )

# decide which variables to use in the models (involves seeing he future, but we'll ignore that for now.)
screen = gbm( D1_admissions ~ ., data=covid[, -1], n.trees=3000, distribution="poisson", interaction.depth=5, n.minobsinnode=3, shrinkage=0.0025, cv.folds=5 )

# show the most influential variables for predicting COVID admissions:
my_summary = summary(screen, plotit=FALSE,
                     n.trees = gbm.perf(screen, plot.it=FALSE) )
print(my_summary)

# use the top ten variables from the screening model
f = paste0("D1_admissions ~ ", paste( my_summary$var[1:10], collapse=" + "))


# use those variables in CV to make a model:
for ( i in 1:nfold ) {
  # Estimate a model for the covid admissions data
  boost = gbm( formula(f), data=covid[ fold < i, ], n.trees=3000, distribution="poisson", interaction.depth=5, n.minobsinnode=3, shrinkage=0.0025, cv.folds=5 )
  
  # make predictions from the covid admissions model
  pred[ fold == i ] = predict(boost, covid, type='response')[ fold == i ]
}

plot(pred, covid$D1_admissions, xlab="prediction", ylab="actual future admissions")
abline(a=0, b=1)
```

The predictions are clearly somewhat muted relative to the actual future admissions, but they do capture the trend and when we look at the admissions from the perspective of the assumed Poisson distribution, we will see that the wider errors toward the right of the plot are expected.





